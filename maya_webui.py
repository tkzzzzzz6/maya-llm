#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éº»é¸­è¯­éŸ³åŠ©æ‰‹ Web UI
Maya Voice Assistant - Modern Web Interface

åŠŸèƒ½ç‰¹æ€§ï¼š
- ğŸ™ï¸ è¯­éŸ³è¯†åˆ« (SenseVoice)
- ğŸ”‘ å…³é”®è¯å”¤é†’ (KWS) 
- ğŸ‘¤ å£°çº¹è¯†åˆ« (CAM++)
- ğŸ¤– æ™ºèƒ½å¯¹è¯ (Qwen2.5)
- ğŸ”Š è¯­éŸ³åˆæˆ (Edge TTS)
- ğŸ’¾ å¯¹è¯è®°å¿†
"""

import gradio as gr
import numpy as np
import torch
import wave
import os
import tempfile
import asyncio
from datetime import datetime
from funasr import AutoModel
from transformers import AutoModelForCausalLM, AutoTokenizer
from modelscope.pipelines import pipeline
from modelscope import snapshot_download
import edge_tts
import pygame
import time
import re
from pypinyin import pinyin, Style
import langid

# ========== é…ç½® ==========
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# å…¨å±€å˜é‡
audio_file_count = 0
conversation_history = []

# ========== å·¥å…·å‡½æ•° ==========

def extract_chinese_and_convert_to_pinyin(input_string):
    """æå–æ±‰å­—å¹¶è½¬æ¢ä¸ºæ‹¼éŸ³"""
    chinese_characters = re.findall(r'[\u4e00-\u9fa5]', input_string)
    chinese_text = ''.join(chinese_characters)
    pinyin_result = pinyin(chinese_text, style=Style.NORMAL)
    pinyin_text = ' '.join([item[0] for item in pinyin_result])
    return pinyin_text

def is_folder_empty(folder_path):
    """æ£€æµ‹æ–‡ä»¶å¤¹æ˜¯å¦ä¸ºç©º"""
    if not os.path.exists(folder_path):
        return True
    entries = os.listdir(folder_path)
    for entry in entries:
        full_path = os.path.join(folder_path, entry)
        if os.path.isfile(full_path):
            return False
    return True

def format_history(history_list):
    """æ ¼å¼åŒ–å¯¹è¯å†å²"""
    if not history_list:
        return "æš‚æ— å¯¹è¯è®°å½•"
    
    formatted = []
    for i, (user_msg, bot_msg, timestamp) in enumerate(history_list, 1):
        formatted.append(f"**[{timestamp}] å¯¹è¯ #{i}**")
        formatted.append(f"ğŸ‘¤ ç”¨æˆ·: {user_msg}")
        formatted.append(f"ğŸ¤– éº»é¸­: {bot_msg}")
        formatted.append("---")
    return "\n".join(formatted)

async def text_to_speech(text, voice="zh-CN-XiaoyiNeural"):
    """å¼‚æ­¥æ–‡å­—è½¬è¯­éŸ³"""
    output_file = tempfile.mktemp(suffix=".mp3")
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(output_file)
    return output_file

# ========== å¯¹è¯è®°å¿†ç±» ==========

class ChatMemory:
    def __init__(self, max_length=2048):
        self.history = []
        self.max_length = max_length

    def add_to_history(self, user_input, model_response):
        self.history.append(f"User: {user_input}")
        self.history.append(f"Assistant: {model_response}")

    def get_context(self):
        context = "\n".join(self.history)
        if len(context) > self.max_length:
            context = context[-self.max_length:]
        return context
    
    def clear(self):
        self.history = []

# ========== æ¨¡å‹ç®¡ç†ç±» ==========

class MayaModels:
    def __init__(self):
        self.models_loaded = False
        self.asr_model = None
        self.llm_model = None
        self.llm_tokenizer = None
        self.sv_pipeline = None
        self.memory = ChatMemory(max_length=512)
        self.sv_enroll_dir = './SpeakerVerification_DIR/enroll_wav/'
        os.makedirs(self.sv_enroll_dir, exist_ok=True)
        os.makedirs('./output', exist_ok=True)
        
    def load_models(self, progress=gr.Progress()):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹"""
        if self.models_loaded:
            return "âœ… æ¨¡å‹å·²åŠ è½½"
        
        try:
            # 1. åŠ è½½ SenseVoice ASR æ¨¡å‹
            progress(0.2, desc="åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹ (SenseVoice)...")
            self.asr_model = AutoModel(
                model="iic/SenseVoiceSmall",
                trust_remote_code=True
            )
            
            # 2. åŠ è½½ CAM++ å£°çº¹è¯†åˆ«æ¨¡å‹
            progress(0.4, desc="åŠ è½½å£°çº¹è¯†åˆ«æ¨¡å‹ (CAM++)...")
            self.sv_pipeline = pipeline(
                task='speaker-verification',
                model='damo/speech_campplus_sv_zh-cn_16k-common',
                model_revision='v1.0.0'
            )
            
            # 3. åŠ è½½ Qwen2.5 å¤§è¯­è¨€æ¨¡å‹
            progress(0.6, desc="åŠ è½½å¤§è¯­è¨€æ¨¡å‹ (Qwen2.5-1.5B)...")
            model_id = "qwen/Qwen2.5-1.5B-Instruct"
            qwen_local_dir = snapshot_download(model_id=model_id)
            
            progress(0.8, desc="åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹...")
            self.llm_model = AutoModelForCausalLM.from_pretrained(
                qwen_local_dir,
                torch_dtype="auto",
                device_map="auto",
                trust_remote_code=True
            )
            self.llm_tokenizer = AutoTokenizer.from_pretrained(
                qwen_local_dir,
                trust_remote_code=True
            )
            
            progress(1.0, desc="æ¨¡å‹åŠ è½½å®Œæˆï¼")
            self.models_loaded = True
            return "âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸï¼"
            
        except Exception as e:
            return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"

# åˆ›å»ºå…¨å±€æ¨¡å‹å®ä¾‹
maya_models = MayaModels()

# ========== æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ==========

def register_voiceprint(audio_file, progress=gr.Progress()):
    """å£°çº¹æ³¨å†Œ"""
    if audio_file is None:
        return "âŒ è¯·å…ˆå½•åˆ¶æˆ–ä¸Šä¼ éŸ³é¢‘", None
    
    try:
        progress(0.3, desc="æ£€æŸ¥éŸ³é¢‘è´¨é‡...")
        
        # æ£€æŸ¥éŸ³é¢‘é•¿åº¦
        with wave.open(audio_file, 'rb') as wf:
            frames = wf.getnframes()
            rate = wf.getframerate()
            duration = frames / float(rate)
        
        if duration < 3:
            return f"âŒ éŸ³é¢‘æ—¶é•¿ä»… {duration:.1f} ç§’ï¼Œéœ€è¦è‡³å°‘ 3 ç§’", None
        
        progress(0.6, desc="ä¿å­˜å£°çº¹ç‰¹å¾...")
        
        # ä¿å­˜å£°çº¹æ–‡ä»¶
        enroll_path = os.path.join(maya_models.sv_enroll_dir, "enroll_0.wav")
        
        # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶
        import shutil
        shutil.copy(audio_file, enroll_path)
        
        progress(1.0, desc="å£°çº¹æ³¨å†Œå®Œæˆï¼")
        
        return f"âœ… å£°çº¹æ³¨å†ŒæˆåŠŸï¼éŸ³é¢‘æ—¶é•¿: {duration:.1f} ç§’", enroll_path
        
    except Exception as e:
        return f"âŒ å£°çº¹æ³¨å†Œå¤±è´¥: {str(e)}", None

def speech_to_text(audio_file, progress=gr.Progress()):
    """è¯­éŸ³è¯†åˆ«"""
    if audio_file is None:
        return "âŒ è¯·å…ˆå½•åˆ¶æˆ–ä¸Šä¼ éŸ³é¢‘"
    
    if not maya_models.models_loaded:
        return "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹"
    
    try:
        progress(0.5, desc="è¯†åˆ«ä¸­...")
        
        res = maya_models.asr_model.generate(
            input=audio_file,
            cache={},
            language="auto",
            use_itn=False,
        )
        
        text = res[0]['text'].split(">")[-1]
        progress(1.0, desc="è¯†åˆ«å®Œæˆï¼")
        
        return text
        
    except Exception as e:
        return f"âŒ è¯†åˆ«å¤±è´¥: {str(e)}"

def verify_speaker(audio_file, threshold=0.35, progress=gr.Progress()):
    """å£°çº¹éªŒè¯"""
    if audio_file is None:
        return "âŒ è¯·å…ˆå½•åˆ¶æˆ–ä¸Šä¼ éŸ³é¢‘", 0.0
    
    if not maya_models.models_loaded:
        return "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹", 0.0
    
    # æ£€æŸ¥æ˜¯å¦å·²æ³¨å†Œå£°çº¹
    enroll_file = os.path.join(maya_models.sv_enroll_dir, "enroll_0.wav")
    if not os.path.exists(enroll_file):
        return "âŒ è¯·å…ˆæ³¨å†Œå£°çº¹", 0.0
    
    try:
        progress(0.5, desc="éªŒè¯ä¸­...")
        
        sv_score = maya_models.sv_pipeline(
            [enroll_file, audio_file],
            thr=threshold
        )
        
        score = sv_score.get('score', 0.0)
        result = sv_score.get('text', 'no')
        
        progress(1.0, desc="éªŒè¯å®Œæˆï¼")
        
        if result == "yes":
            return f"âœ… å£°çº¹éªŒè¯é€šè¿‡ (ç›¸ä¼¼åº¦: {score:.2f})", score
        else:
            return f"âŒ å£°çº¹éªŒè¯å¤±è´¥ (ç›¸ä¼¼åº¦: {score:.2f})", score
            
    except Exception as e:
        return f"âŒ éªŒè¯å¤±è´¥: {str(e)}", 0.0

def check_wake_word(text, wake_word="ç«™èµ·æ¥"):
    """æ£€æŸ¥å”¤é†’è¯"""
    text_pinyin = extract_chinese_and_convert_to_pinyin(text)
    wake_word_pinyin = extract_chinese_and_convert_to_pinyin(wake_word)
    
    wake_word_pinyin = wake_word_pinyin.replace(" ", "")
    text_pinyin = text_pinyin.replace(" ", "")
    
    if wake_word_pinyin in text_pinyin:
        return True, f"âœ… æ£€æµ‹åˆ°å”¤é†’è¯: {wake_word}"
    else:
        return False, f"âŒ æœªæ£€æµ‹åˆ°å”¤é†’è¯ (éœ€è¦: {wake_word})"

def chat_with_maya(
    text_input=None,
    audio_input=None,
    enable_kws=True,
    wake_word="ç«™èµ·æ¥",
    enable_sv=True,
    sv_threshold=0.35,
    enable_tts=True,
    system_prompt="ä½ å«å°åƒï¼Œæ˜¯ä¸€ä¸ª18å²çš„å¥³å¤§å­¦ç”Ÿï¼Œæ€§æ ¼æ´»æ³¼å¼€æœ—ï¼Œè¯´è¯ä¿çš®ç®€æ´ï¼Œå›ç­”é—®é¢˜ä¸ä¼šè¶…è¿‡50å­—ã€‚",
    progress=gr.Progress()
):
    """ä¸»å¯¹è¯å‡½æ•°"""
    global conversation_history, audio_file_count
    
    if not maya_models.models_loaded:
        return "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹", None, format_history(conversation_history)
    
    user_text = text_input
    
    # 1. è¯­éŸ³è¯†åˆ«
    if audio_input is not None:
        progress(0.1, desc="è¯­éŸ³è¯†åˆ«ä¸­...")
        user_text = speech_to_text(audio_input)
        if user_text.startswith("âŒ"):
            return user_text, None, format_history(conversation_history)
    
    if not user_text or user_text.strip() == "":
        return "âŒ è¯·è¾“å…¥æ–‡å­—æˆ–å½•åˆ¶è¯­éŸ³", None, format_history(conversation_history)
    
    # 2. å…³é”®è¯å”¤é†’æ£€æµ‹
    if enable_kws:
        progress(0.2, desc="æ£€æµ‹å”¤é†’è¯...")
        kws_pass, kws_msg = check_wake_word(user_text, wake_word)
        if not kws_pass:
            return kws_msg, None, format_history(conversation_history)
    
    # 3. å£°çº¹éªŒè¯
    if enable_sv and audio_input is not None:
        progress(0.3, desc="å£°çº¹éªŒè¯ä¸­...")
        sv_msg, sv_score = verify_speaker(audio_input, sv_threshold)
        if not sv_msg.startswith("âœ…"):
            return sv_msg, None, format_history(conversation_history)
    
    # 4. å¤§è¯­è¨€æ¨¡å‹æ¨ç†
    progress(0.5, desc="æ€è€ƒä¸­...")
    
    try:
        # è·å–å†å²å¯¹è¯ä¸Šä¸‹æ–‡
        context = maya_models.memory.get_context()
        prompt_with_context = f"{context}\nUser: {user_text}\n" if context else user_text
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt_with_context},
        ]
        
        text = maya_models.llm_tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True,
        )
        
        model_inputs = maya_models.llm_tokenizer([text], return_tensors="pt").to(
            maya_models.llm_model.device
        )
        
        generated_ids = maya_models.llm_model.generate(
            **model_inputs,
            max_new_tokens=512,
        )
        
        generated_ids = [
            output_ids[len(input_ids):]
            for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
        ]
        
        output_text = maya_models.llm_tokenizer.batch_decode(
            generated_ids, skip_special_tokens=True
        )[0]
        
        # æ›´æ–°è®°å¿†
        maya_models.memory.add_to_history(user_text, output_text)
        
        # ä¿å­˜å¯¹è¯å†å²
        timestamp = datetime.now().strftime("%H:%M:%S")
        conversation_history.append((user_text, output_text, timestamp))
        
        # 5. è¯­éŸ³åˆæˆ
        audio_output = None
        if enable_tts:
            progress(0.8, desc="ç”Ÿæˆè¯­éŸ³ä¸­...")
            
            # è¯­ç§è¯†åˆ«
            language, _ = langid.classify(output_text)
            
            language_speaker = {
                "ja": "ja-JP-NanamiNeural",
                "fr": "fr-FR-DeniseNeural",
                "es": "ca-ES-JoanaNeural",
                "de": "de-DE-KatjaNeural",
                "zh": "zh-CN-XiaoyiNeural",
                "en": "en-US-AnaNeural",
            }
            
            voice = language_speaker.get(language, "zh-CN-XiaoyiNeural")
            
            audio_file_count += 1
            audio_output = asyncio.run(text_to_speech(output_text, voice))
        
        progress(1.0, desc="å®Œæˆï¼")
        
        return output_text, audio_output, format_history(conversation_history)
        
    except Exception as e:
        return f"âŒ å¯¹è¯å¤±è´¥: {str(e)}", None, format_history(conversation_history)

def clear_history():
    """æ¸…ç©ºå¯¹è¯å†å²"""
    global conversation_history
    conversation_history = []
    maya_models.memory.clear()
    return "", format_history(conversation_history)

# ========== Gradio ç•Œé¢ ==========

def create_ui():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    # è‡ªå®šä¹‰ CSS
    custom_css = """
    .gradio-container {
        font-family: 'Microsoft YaHei', 'PingFang SC', sans-serif;
    }
    .header-title {
        text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 3em;
        font-weight: bold;
        margin-bottom: 0.5em;
    }
    .header-subtitle {
        text-align: center;
        color: #666;
        font-size: 1.2em;
        margin-bottom: 2em;
    }
    .feature-box {
        background: linear-gradient(135deg, #667eea22 0%, #764ba222 100%);
        padding: 1em;
        border-radius: 10px;
        margin: 0.5em 0;
    }
    .status-box {
        padding: 1em;
        border-radius: 8px;
        margin: 0.5em 0;
        font-weight: bold;
    }
    """
    
    with gr.Blocks(css=custom_css, title="éº»é¸­è¯­éŸ³åŠ©æ‰‹", theme=gr.themes.Soft()) as demo:
        
        # æ ‡é¢˜åŒºåŸŸ
        gr.HTML("""
        <div class="header-title">ğŸ¦† éº»é¸­è¯­éŸ³åŠ©æ‰‹</div>
        <div class="header-subtitle">Maya Voice Assistant - åŸºäºéº»é¸­è¯­æ–™å¾®è°ƒçš„æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹</div>
        """)
        
        # åŠŸèƒ½ä»‹ç»
        with gr.Row():
            gr.Markdown("""
            ### âœ¨ æ ¸å¿ƒåŠŸèƒ½
            - ğŸ™ï¸ **è¯­éŸ³è¯†åˆ«**: SenseVoice é«˜ç²¾åº¦è¯†åˆ«
            - ğŸ”‘ **å…³é”®è¯å”¤é†’**: è‡ªå®šä¹‰å”¤é†’è¯ï¼Œä¿æŠ¤éšç§
            - ğŸ‘¤ **å£°çº¹è¯†åˆ«**: CAM++ å£°çº¹éªŒè¯ï¼Œä¸“å±åŠ©æ‰‹
            - ğŸ¤– **æ™ºèƒ½å¯¹è¯**: Qwen2.5 å¤§æ¨¡å‹ï¼Œä¸Šä¸‹æ–‡è®°å¿†
            - ğŸ”Š **è¯­éŸ³åˆæˆ**: Edge TTS å¤šè¯­ç§è‡ªç„¶è¯­éŸ³
            """)
        
        # ç¬¬ä¸€æ­¥ï¼šæ¨¡å‹åŠ è½½
        with gr.Tab("ğŸ“¦ 1. æ¨¡å‹åŠ è½½"):
            gr.Markdown("### é¦–æ¬¡ä½¿ç”¨è¯·å…ˆåŠ è½½æ¨¡å‹ï¼ˆçº¦éœ€1-3åˆ†é’Ÿï¼‰")
            
            load_btn = gr.Button("ğŸš€ åŠ è½½æ‰€æœ‰æ¨¡å‹", variant="primary", size="lg")
            load_status = gr.Textbox(label="åŠ è½½çŠ¶æ€", lines=2, interactive=False)
            
            load_btn.click(
                fn=maya_models.load_models,
                outputs=load_status
            )
        
        # ç¬¬äºŒæ­¥ï¼šå£°çº¹æ³¨å†Œ
        with gr.Tab("ğŸ‘¤ 2. å£°çº¹æ³¨å†Œ (å¯é€‰)"):
            gr.Markdown("""
            ### æ³¨å†Œæ‚¨çš„å£°çº¹ï¼Œè®©åŠ©æ‰‹åªå¬ä½ çš„æŒ‡ä»¤
            - å½•åˆ¶æˆ–ä¸Šä¼  **3-10ç§’** çš„æ¸…æ™°è¯­éŸ³
            - å»ºè®®è¯´ä¸€æ®µå®Œæ•´çš„è¯ï¼Œå¦‚"ä½ å¥½ï¼Œæˆ‘æ˜¯[ä½ çš„åå­—]ï¼Œè¿™æ˜¯æˆ‘çš„å£°çº¹"
            """)
            
            with gr.Row():
                with gr.Column():
                    voiceprint_audio = gr.Audio(
                        source="microphone",  # Gradio 3.x å…¼å®¹
                        type="filepath",
                        label="å½•åˆ¶æˆ–ä¸Šä¼ éŸ³é¢‘ (â‰¥3ç§’)"
                    )
                    register_btn = gr.Button("âœ… æ³¨å†Œå£°çº¹", variant="primary")
                
                with gr.Column():
                    register_status = gr.Textbox(label="æ³¨å†ŒçŠ¶æ€", lines=2)
                    voiceprint_file = gr.File(label="å·²ä¿å­˜çš„å£°çº¹æ–‡ä»¶")
            
            register_btn.click(
                fn=register_voiceprint,
                inputs=voiceprint_audio,
                outputs=[register_status, voiceprint_file]
            )
        
        # ç¬¬ä¸‰æ­¥ï¼šå¯¹è¯äº¤äº’
        with gr.Tab("ğŸ’¬ 3. å¼€å§‹å¯¹è¯"):
            gr.Markdown("### ä¸éº»é¸­è¯­éŸ³åŠ©æ‰‹å¯¹è¯")
            
            with gr.Row():
                # å·¦ä¾§ï¼šè¾“å…¥åŒº
                with gr.Column(scale=1):
                    gr.Markdown("#### ğŸ“ è¾“å…¥æ–¹å¼")
                    
                    text_input = gr.Textbox(
                        label="æ–‡å­—è¾“å…¥",
                        placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜...",
                        lines=3
                    )
                    
                    audio_input = gr.Audio(
                        source="microphone",  # Gradio 3.x å…¼å®¹
                        type="filepath",
                        label="è¯­éŸ³è¾“å…¥"
                    )
                    
                    with gr.Accordion("âš™ï¸ é«˜çº§è®¾ç½®", open=False):
                        enable_kws = gr.Checkbox(
                            label="å¯ç”¨å…³é”®è¯å”¤é†’",
                            value=True,
                            info="éœ€è¦è¯´å‡ºå”¤é†’è¯æ‰èƒ½å“åº”"
                        )
                        wake_word = gr.Textbox(
                            label="å”¤é†’è¯",
                            value="ç«™èµ·æ¥",
                            placeholder="è¾“å…¥å”¤é†’è¯ï¼ˆä¸­æ–‡ï¼‰"
                        )
                        
                        enable_sv = gr.Checkbox(
                            label="å¯ç”¨å£°çº¹éªŒè¯",
                            value=False,
                            info="ä»…æ³¨å†Œç”¨æˆ·å¯ä½¿ç”¨"
                        )
                        sv_threshold = gr.Slider(
                            minimum=0.1,
                            maximum=0.9,
                            value=0.35,
                            step=0.05,
                            label="å£°çº¹ç›¸ä¼¼åº¦é˜ˆå€¼",
                            info="è¶Šé«˜è¶Šä¸¥æ ¼"
                        )
                        
                        enable_tts = gr.Checkbox(
                            label="å¯ç”¨è¯­éŸ³åˆæˆ",
                            value=True,
                            info="ç”Ÿæˆè¯­éŸ³å›å¤"
                        )
                        
                        system_prompt = gr.Textbox(
                            label="ç³»ç»Ÿæç¤ºè¯",
                            value="ä½ å«å°åƒï¼Œæ˜¯ä¸€ä¸ª18å²çš„å¥³å¤§å­¦ç”Ÿï¼Œæ€§æ ¼æ´»æ³¼å¼€æœ—ï¼Œè¯´è¯ä¿çš®ç®€æ´ï¼Œå›ç­”é—®é¢˜ä¸ä¼šè¶…è¿‡50å­—ã€‚",
                            lines=3
                        )
                    
                    chat_btn = gr.Button("ğŸš€ å‘é€", variant="primary", size="lg")
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå†å²", variant="secondary")
                
                # å³ä¾§ï¼šè¾“å‡ºåŒº
                with gr.Column(scale=1):
                    gr.Markdown("#### ğŸ’¬ åŠ©æ‰‹å›å¤")
                    
                    text_output = gr.Textbox(
                        label="æ–‡å­—å›å¤",
                        lines=5,
                        interactive=False
                    )
                    
                    audio_output = gr.Audio(
                        label="è¯­éŸ³å›å¤",
                        autoplay=True
                    )
                    
                    history_output = gr.Markdown(
                        label="å¯¹è¯å†å²",
                        value="æš‚æ— å¯¹è¯è®°å½•"
                    )
            
            # ç»‘å®šäº‹ä»¶
            chat_btn.click(
                fn=chat_with_maya,
                inputs=[
                    text_input,
                    audio_input,
                    enable_kws,
                    wake_word,
                    enable_sv,
                    sv_threshold,
                    enable_tts,
                    system_prompt
                ],
                outputs=[text_output, audio_output, history_output]
            )
            
            clear_btn.click(
                fn=clear_history,
                outputs=[text_output, history_output]
            )
        
        # ç¬¬å››æ­¥ï¼šæµ‹è¯•åŠŸèƒ½
        with gr.Tab("ğŸ”§ 4. åŠŸèƒ½æµ‹è¯•"):
            gr.Markdown("### å•ç‹¬æµ‹è¯•å„é¡¹åŠŸèƒ½")
            
            with gr.Row():
                # è¯­éŸ³è¯†åˆ«æµ‹è¯•
                with gr.Column():
                    gr.Markdown("#### ğŸ™ï¸ è¯­éŸ³è¯†åˆ«æµ‹è¯•")
                    test_asr_audio = gr.Audio(
                        source="microphone",  # Gradio 3.x å…¼å®¹
                        type="filepath",
                        label="æµ‹è¯•éŸ³é¢‘"
                    )
                    test_asr_btn = gr.Button("è¯†åˆ«", variant="primary")
                    test_asr_output = gr.Textbox(label="è¯†åˆ«ç»“æœ", lines=3)
                    
                    test_asr_btn.click(
                        fn=speech_to_text,
                        inputs=test_asr_audio,
                        outputs=test_asr_output
                    )
                
                # å£°çº¹éªŒè¯æµ‹è¯•
                with gr.Column():
                    gr.Markdown("#### ğŸ‘¤ å£°çº¹éªŒè¯æµ‹è¯•")
                    test_sv_audio = gr.Audio(
                        source="microphone",  # Gradio 3.x å…¼å®¹
                        type="filepath",
                        label="æµ‹è¯•éŸ³é¢‘"
                    )
                    test_sv_threshold = gr.Slider(
                        minimum=0.1,
                        maximum=0.9,
                        value=0.35,
                        step=0.05,
                        label="é˜ˆå€¼"
                    )
                    test_sv_btn = gr.Button("éªŒè¯", variant="primary")
                    test_sv_output = gr.Textbox(label="éªŒè¯ç»“æœ", lines=3)
                    
                    test_sv_btn.click(
                        fn=verify_speaker,
                        inputs=[test_sv_audio, test_sv_threshold],
                        outputs=test_sv_output
                    )
        
        # ä½¿ç”¨è¯´æ˜
        with gr.Tab("ğŸ“– ä½¿ç”¨è¯´æ˜"):
            gr.Markdown("""
            ## ğŸ“– ä½¿ç”¨æŒ‡å—
            
            ### å¿«é€Ÿå¼€å§‹ï¼ˆ4æ­¥ï¼‰
            
            #### 1ï¸âƒ£ åŠ è½½æ¨¡å‹
            - ç‚¹å‡»"æ¨¡å‹åŠ è½½"æ ‡ç­¾é¡µ
            - ç‚¹å‡»"åŠ è½½æ‰€æœ‰æ¨¡å‹"æŒ‰é’®
            - ç­‰å¾…1-3åˆ†é’Ÿï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰
            
            #### 2ï¸âƒ£ æ³¨å†Œå£°çº¹ï¼ˆå¯é€‰ï¼‰
            - å¦‚æœéœ€è¦å£°çº¹éªŒè¯åŠŸèƒ½ï¼Œåœ¨"å£°çº¹æ³¨å†Œ"é¡µé¢å½•åˆ¶3-10ç§’éŸ³é¢‘
            - ç‚¹å‡»"æ³¨å†Œå£°çº¹"
            
            #### 3ï¸âƒ£ å¼€å§‹å¯¹è¯
            - åˆ‡æ¢åˆ°"å¼€å§‹å¯¹è¯"æ ‡ç­¾é¡µ
            - æ–‡å­—è¾“å…¥æˆ–è¯­éŸ³å½•åˆ¶æ‚¨çš„é—®é¢˜
            - ç¡®ä¿è¯´å‡ºå”¤é†’è¯ï¼ˆé»˜è®¤"ç«™èµ·æ¥"ï¼‰
            - ç‚¹å‡»"å‘é€"
            
            #### 4ï¸âƒ£ é«˜çº§è®¾ç½®
            - å±•å¼€"é«˜çº§è®¾ç½®"å¯ä»¥ï¼š
              - è‡ªå®šä¹‰å”¤é†’è¯
              - è°ƒæ•´å£°çº¹éªŒè¯é˜ˆå€¼
              - ä¿®æ”¹AIäººè®¾
            
            ---
            
            ### âš™ï¸ åŠŸèƒ½è¯´æ˜
            
            #### ğŸ”‘ å…³é”®è¯å”¤é†’
            - **ç”¨é€”**: ä¿æŠ¤éšç§ï¼Œé¿å…è¯¯è§¦å‘
            - **ä½¿ç”¨**: åœ¨å¯¹è¯ä¸­åŒ…å«å”¤é†’è¯ï¼Œå¦‚"ç«™èµ·æ¥ï¼Œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
            - **è‡ªå®šä¹‰**: å¯åœ¨é«˜çº§è®¾ç½®ä¸­ä¿®æ”¹å”¤é†’è¯
            
            #### ğŸ‘¤ å£°çº¹è¯†åˆ«
            - **ç”¨é€”**: ç¡®ä¿åªæœ‰æ³¨å†Œç”¨æˆ·å¯ä»¥ä½¿ç”¨
            - **ä½¿ç”¨**: æ³¨å†Œå£°çº¹åï¼Œå¯ç”¨"å£°çº¹éªŒè¯"ï¼Œåªç”¨è¯­éŸ³è¾“å…¥æ‰ä¼šéªŒè¯
            - **é˜ˆå€¼**: 0.35ä¸ºæ¨èå€¼ï¼Œå¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼ˆè¶Šé«˜è¶Šä¸¥æ ¼ï¼‰
            
            #### ğŸ’¾ å¯¹è¯è®°å¿†
            - è‡ªåŠ¨è®°ä½å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘512å­—ï¼‰
            - æ”¯æŒå¤šè½®å¯¹è¯
            - ç‚¹å‡»"æ¸…ç©ºå†å²"é‡ç½®å¯¹è¯
            
            #### ğŸŒ å¤šè¯­è¨€æ”¯æŒ
            - è‡ªåŠ¨è¯†åˆ«å›å¤è¯­ç§
            - æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ã€æ—¥è¯­ã€æ³•è¯­ã€å¾·è¯­ã€è¥¿ç­ç‰™è¯­
            
            ---
            
            ### âš ï¸ å¸¸è§é—®é¢˜
            
            **Q: æ¨¡å‹åŠ è½½å¾ˆæ…¢ï¼Ÿ**  
            A: é¦–æ¬¡è¿è¡Œéœ€è¦ä» ModelScope ä¸‹è½½æ¨¡å‹ï¼ˆçº¦2-3GBï¼‰ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚åç»­å¯åŠ¨ä¼šç›´æ¥ä½¿ç”¨ç¼“å­˜ã€‚
            
            **Q: å”¤é†’è¯ä¸ç”Ÿæ•ˆï¼Ÿ**  
            A: ç¡®ä¿å”¤é†’è¯æ˜¯ä¸­æ–‡ï¼Œå¹¶ä¸”åœ¨å¯¹è¯ä¸­åŒ…å«å®Œæ•´çš„å”¤é†’è¯æ‹¼éŸ³ã€‚
            
            **Q: å£°çº¹éªŒè¯æ€»æ˜¯å¤±è´¥ï¼Ÿ**  
            A: å°è¯•é™ä½é˜ˆå€¼ï¼Œæˆ–é‡æ–°æ³¨å†Œæ›´æ¸…æ™°çš„å£°çº¹ã€‚
            
            **Q: æ²¡æœ‰éº¦å…‹é£æ€ä¹ˆåŠï¼Ÿ**  
            A: å¯ä»¥ä½¿ç”¨æ–‡å­—è¾“å…¥ï¼Œæˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ã€‚
            
            ---
            
            ### ğŸ¯ ä½¿ç”¨æŠ€å·§
            
            1. **ä»…ä½¿ç”¨æ–‡å­—å¯¹è¯**: å…³é—­"å¯ç”¨å…³é”®è¯å”¤é†’"å’Œ"å¯ç”¨å£°çº¹éªŒè¯"
            2. **å…¬å…±åœºåˆä½¿ç”¨**: å…³é—­"å¯ç”¨è¯­éŸ³åˆæˆ"ï¼Œä»…çœ‹æ–‡å­—å›å¤
            3. **ä¸ªæ€§åŒ–AI**: ä¿®æ”¹"ç³»ç»Ÿæç¤ºè¯"æ”¹å˜AIçš„æ€§æ ¼å’Œé£æ ¼
            4. **æé«˜è¯†åˆ«ç‡**: å½•éŸ³æ—¶ä¿æŒå®‰é™ç¯å¢ƒï¼Œæ¸…æ™°å‘éŸ³
            
            ---
            
            ### ğŸ“ æŠ€æœ¯æ”¯æŒ
            
            - **é¡¹ç›®åœ°å€**: GitHub / ModelScope
            - **é—®é¢˜åé¦ˆ**: æäº¤ Issue
            - **æŠ€æœ¯æ–‡æ¡£**: æŸ¥çœ‹ `docs/` ç›®å½•
            
            ---
            
            ğŸ¦† **éº»é¸­è¯­éŸ³åŠ©æ‰‹** - è®©å¯¹è¯æ›´æ™ºèƒ½ï¼Œæ›´è‡ªç„¶ï¼
            """)
        
        # é¡µè„š
        gr.Markdown("""
        ---
        <div style="text-align: center; color: #666; padding: 1em;">
            ğŸ¦† éº»é¸­è¯­éŸ³åŠ©æ‰‹ v1.0 | åŸºäº SenseVoice + CAM++ + Qwen2.5 + Edge TTS<br>
            Powered by ModelScope & Gradio | Made with â¤ï¸
        </div>
        """)
    
    return demo

# ========== ä¸»å‡½æ•° ==========

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="éº»é¸­è¯­éŸ³åŠ©æ‰‹ Web UI")
    parser.add_argument("--port", type=int, default=7860, help="ç«¯å£å·")
    parser.add_argument("--share", action="store_true", help="ç”Ÿæˆå…¬ç½‘é“¾æ¥")
    parser.add_argument("--server-name", type=str, default="0.0.0.0", help="æœåŠ¡å™¨åœ°å€")
    args = parser.parse_args()
    
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘     ğŸ¦† éº»é¸­è¯­éŸ³åŠ©æ‰‹ Web UI           â•‘
    â•‘   Maya Voice Assistant v1.0          â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    demo = create_ui()
    
    # å¯ç”¨é˜Ÿåˆ—ä»¥æ”¯æŒ Progress åŠŸèƒ½
    demo.queue(concurrency_count=3, max_size=10)
    
    demo.launch(
        server_name=args.server_name,
        server_port=args.port,
        share=args.share,
        favicon_path=None,
        show_error=True
    )

